# 机器学习概论#

1. 算法设计

   本次作业实现了比较基本的决策树算法

   1. 特征提取

      将文档提取成18维的向量

      首先计算训练样本中所有词的TF-IDF

      从每一类中选取TF-IDF值最高的两个作为特征

   2. 相似度计算

      计算所有词和18维特征的相似程度$\mathit{simi}(x,y) = \log\frac{p(x|y)}{p(x)}$

      考虑到未同时出现在一篇文档里的词组太多，所以对于出现在同一类下的词组做了相应的调整

   3. 文档向量化

      将文档中的所有词与所有特征的相似度加权求和

   4. 决策树生成

      做了9棵决策树，每棵决策树做相应类别的二分类

      每一棵决策树的节点均是考虑从所有特征中选择一个阈值分类，得到最大的gain

      一篇新的文档决策完成会得到一个9维的向量，每一维为0或1，0表示不属于这一类，1表示属于这一类
   
2. 测试

   将weibo.py放在微博同一目录下

   将90%的数据作为训练集，剩余10%的数据作为测试，共运行10次

   | 次数 | 正确率     |
   | ---- | ---------- |
   | 0    | 68.2%      |
   | 1    | 69.8%      |
   | 2    | 70.1%      |
   | 3    | 66.8%      |
   | 4    | 70.1%      |
   | 5    | 68.7%      |
   | 6    | 67.9%      |
   | 7    | 70.8%      |
   | 8    | 68.1%      |
   | 9    | 69.7%      |
   | 均值 | 69.0%      |
   | 方差 | 0.00014376 |

   暂时没有对比与标准库的差别

   目前的结果比较稳定，在测试集上达到了69%的正确率

   首先特征的提取可能存在改进的地方，毕竟将文档向量化的过程方法还有许多，如果能在提取特征的部分中就将不同的类能够明显的划分，那么使用决策树可能有更好的结果

   将文档向量化之后做分类的方法很多，可能决策树已经不是那么必要了